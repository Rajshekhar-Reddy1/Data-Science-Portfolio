{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chat-Bots with Python.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shantanu9326/Data-Science-Portfolio/blob/master/Chat_Bots_with_Python.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Ql-oQTqyv2M",
        "colab_type": "text"
      },
      "source": [
        "# Question and Answer Chat Bots"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hx8hpUGjyv2O",
        "colab_type": "text"
      },
      "source": [
        "## Loading the Data\n",
        "\n",
        "We will be working with the Babi Data Set from Facebook Research.\n",
        "\n",
        "Full Details: https://research.fb.com/downloads/babi/\n",
        "\n",
        "- Jason Weston, Antoine Bordes, Sumit Chopra, Tomas Mikolov, Alexander M. Rush,\n",
        "  \"Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks\",\n",
        "  http://arxiv.org/abs/1502.05698\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEvF1_W_yv2O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q08KHHzLz9Dp",
        "colab_type": "code",
        "outputId": "d242b9df-dddc-4d7f-9ae3-62576870e2fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Running or Importing .py Files with Google Colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-sLRiVT5yv2Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(\"/content/drive/My Drive/app/train_qa.txt\", \"rb\") as fp:   # Unpickling\n",
        "    train_data =  pickle.load(fp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3MRZHMQyv2S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(\"/content/drive/My Drive/app/test_qa.txt\", \"rb\") as fp:   # Unpickling\n",
        "    test_data =  pickle.load(fp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dd6eYRtIyv2U",
        "colab_type": "text"
      },
      "source": [
        "## Exploring the Format of the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_m2wk4Byv2U",
        "colab_type": "code",
        "outputId": "4861afcd-da32-4d12-95c4-42820aa1b364",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "type(test_data)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ia1HhExVyv2X",
        "colab_type": "code",
        "outputId": "f3d913cb-525b-489c-a4da-cbc51a6a0520",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "type(train_data)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJ9ZA_iDyv2Z",
        "colab_type": "code",
        "outputId": "c2a2d2b0-c95a-425b-de83-461df93b1444",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(test_data)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqWJsAYMyv2b",
        "colab_type": "code",
        "outputId": "cdce4f90-85af-4690-8a82-dedd6784d5a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(train_data)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NG1GTEnLyv2e",
        "colab_type": "code",
        "outputId": "c6dc690b-552d-4fa3-d798-ee95982bdccf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "train_data[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['Mary',\n",
              "  'moved',\n",
              "  'to',\n",
              "  'the',\n",
              "  'bathroom',\n",
              "  '.',\n",
              "  'Sandra',\n",
              "  'journeyed',\n",
              "  'to',\n",
              "  'the',\n",
              "  'bedroom',\n",
              "  '.'],\n",
              " ['Is', 'Sandra', 'in', 'the', 'hallway', '?'],\n",
              " 'no')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fx7ot-HAyv2g",
        "colab_type": "code",
        "outputId": "00930d87-1dfb-4dd4-bc61-084456308ffe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "' '.join(train_data[0][0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Mary moved to the bathroom . Sandra journeyed to the bedroom .'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6v2GmUhzyv2i",
        "colab_type": "code",
        "outputId": "4044f324-e530-413e-b1a1-96b6ed3d8a41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "' '.join(train_data[0][1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Is Sandra in the hallway ?'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mmutvixhyv2k",
        "colab_type": "code",
        "outputId": "545f9f86-3472-4f07-c446-c023ab4975cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_data[0][2]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'no'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gr-9KS-byv2m",
        "colab_type": "text"
      },
      "source": [
        "## Setting up Vocabulary of All Words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLA97DROyv2n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a set that holds the vocab words\n",
        "vocab = set()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEOphpvAyv2p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_data = test_data + train_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJGAJKZoyv2r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for story, question , answer in all_data:\n",
        "    # In case you don't know what a union of sets is:\n",
        "    # https://www.programiz.com/python-programming/methods/set/union\n",
        "    vocab = vocab.union(set(story))\n",
        "    vocab = vocab.union(set(question))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85sLPLfLyv2u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab.add('no')\n",
        "vocab.add('yes')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BhqcEUiByv2v",
        "colab_type": "code",
        "outputId": "4a3d2b02-5951-4b25-e7fe-ef9a19489688",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        }
      },
      "source": [
        "vocab"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'.',\n",
              " '?',\n",
              " 'Daniel',\n",
              " 'Is',\n",
              " 'John',\n",
              " 'Mary',\n",
              " 'Sandra',\n",
              " 'apple',\n",
              " 'back',\n",
              " 'bathroom',\n",
              " 'bedroom',\n",
              " 'discarded',\n",
              " 'down',\n",
              " 'dropped',\n",
              " 'football',\n",
              " 'garden',\n",
              " 'got',\n",
              " 'grabbed',\n",
              " 'hallway',\n",
              " 'in',\n",
              " 'journeyed',\n",
              " 'kitchen',\n",
              " 'left',\n",
              " 'milk',\n",
              " 'moved',\n",
              " 'no',\n",
              " 'office',\n",
              " 'picked',\n",
              " 'put',\n",
              " 'the',\n",
              " 'there',\n",
              " 'to',\n",
              " 'took',\n",
              " 'travelled',\n",
              " 'up',\n",
              " 'went',\n",
              " 'yes'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hj7mZ-Xxyv2y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_len = len(vocab) + 1 #we add an extra space to hold a 0 for Keras's pad_sequences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Re_dbSNIyv20",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_story_len = max([len(data[0]) for data in all_data])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkUlwcVFyv22",
        "colab_type": "code",
        "outputId": "dfbd9165-51f8-4707-f323-06f9c8c89ad8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "max_story_len"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "156"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1i6WQXWxyv24",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_question_len = max([len(data[1]) for data in all_data])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-9X0QBlyv26",
        "colab_type": "code",
        "outputId": "8c97d6cf-708f-4fa8-81ab-45aa0d99cc95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "max_question_len"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDytkkBbyv28",
        "colab_type": "text"
      },
      "source": [
        "## Vectorizing the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTOjjDkRyv2-",
        "colab_type": "code",
        "outputId": "d5beb826-df2a-4a8a-c4f7-c033f0a8c39a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        }
      },
      "source": [
        "vocab"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'.',\n",
              " '?',\n",
              " 'Daniel',\n",
              " 'Is',\n",
              " 'John',\n",
              " 'Mary',\n",
              " 'Sandra',\n",
              " 'apple',\n",
              " 'back',\n",
              " 'bathroom',\n",
              " 'bedroom',\n",
              " 'discarded',\n",
              " 'down',\n",
              " 'dropped',\n",
              " 'football',\n",
              " 'garden',\n",
              " 'got',\n",
              " 'grabbed',\n",
              " 'hallway',\n",
              " 'in',\n",
              " 'journeyed',\n",
              " 'kitchen',\n",
              " 'left',\n",
              " 'milk',\n",
              " 'moved',\n",
              " 'no',\n",
              " 'office',\n",
              " 'picked',\n",
              " 'put',\n",
              " 'the',\n",
              " 'there',\n",
              " 'to',\n",
              " 'took',\n",
              " 'travelled',\n",
              " 'up',\n",
              " 'went',\n",
              " 'yes'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZtHsfLoyv3A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Reserve 0 for pad_sequences\n",
        "vocab_size = len(vocab) + 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "onaB1jvWyv3B",
        "colab_type": "text"
      },
      "source": [
        "-----------"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fz6C-_V1yv3C",
        "colab_type": "code",
        "outputId": "2c4f2785-a0d7-46b1-9a31-99fe6975b866",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing.text import Tokenizer"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQGxgLI-yv3D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# integer encode sequences of words\n",
        "tokenizer = Tokenizer(filters=[])\n",
        "tokenizer.fit_on_texts(vocab)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grqLthrTyv3F",
        "colab_type": "code",
        "outputId": "a84dfcbc-5c53-4518-8447-fb696b6e7dfa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        }
      },
      "source": [
        "tokenizer.word_index"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'.': 10,\n",
              " '?': 28,\n",
              " 'apple': 21,\n",
              " 'back': 1,\n",
              " 'bathroom': 8,\n",
              " 'bedroom': 19,\n",
              " 'daniel': 31,\n",
              " 'discarded': 17,\n",
              " 'down': 27,\n",
              " 'dropped': 16,\n",
              " 'football': 15,\n",
              " 'garden': 2,\n",
              " 'got': 18,\n",
              " 'grabbed': 9,\n",
              " 'hallway': 14,\n",
              " 'in': 5,\n",
              " 'is': 4,\n",
              " 'john': 26,\n",
              " 'journeyed': 25,\n",
              " 'kitchen': 20,\n",
              " 'left': 12,\n",
              " 'mary': 11,\n",
              " 'milk': 6,\n",
              " 'moved': 36,\n",
              " 'no': 23,\n",
              " 'office': 32,\n",
              " 'picked': 13,\n",
              " 'put': 30,\n",
              " 'sandra': 33,\n",
              " 'the': 37,\n",
              " 'there': 22,\n",
              " 'to': 24,\n",
              " 'took': 35,\n",
              " 'travelled': 7,\n",
              " 'up': 34,\n",
              " 'went': 3,\n",
              " 'yes': 29}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBkntUOcyv3H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_story_text = []\n",
        "train_question_text = []\n",
        "train_answers = []\n",
        "\n",
        "for story,question,answer in train_data:\n",
        "    train_story_text.append(story)\n",
        "    train_question_text.append(question)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5N1hN79yv3I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_story_seq = tokenizer.texts_to_sequences(train_story_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WN6sp2ZXyv3J",
        "colab_type": "code",
        "outputId": "45f4d4d0-4d16-4374-9847-21a3603d2ea7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(train_story_text)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R6aUifLuyv3L",
        "colab_type": "code",
        "outputId": "1b6d68cc-b482-445d-854f-68d54f10fc70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(train_story_seq)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6S2uQ5Hyv3M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# word_index = tokenizer.word_index"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MqFGlGJKyv3N",
        "colab_type": "text"
      },
      "source": [
        "### Functionalize Vectorization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_rTff3jyv3O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def vectorize_stories(data, word_index=tokenizer.word_index, max_story_len=max_story_len,max_question_len=max_question_len):\n",
        "    '''\n",
        "    INPUT: \n",
        "    \n",
        "    data: consisting of Stories,Queries,and Answers\n",
        "    word_index: word index dictionary from tokenizer\n",
        "    max_story_len: the length of the longest story (used for pad_sequences function)\n",
        "    max_question_len: length of the longest question (used for pad_sequences function)\n",
        "\n",
        "\n",
        "    OUTPUT:\n",
        "    \n",
        "    Vectorizes the stories,questions, and answers into padded sequences. We first loop for every story, query , and\n",
        "    answer in the data. Then we convert the raw words to an word index value. Then we append each set to their appropriate\n",
        "    output list. Then once we have converted the words to numbers, we pad the sequences so they are all of equal length.\n",
        "    \n",
        "    Returns this in the form of a tuple (X,Xq,Y) (padded based on max lengths)\n",
        "    '''\n",
        "    \n",
        "    \n",
        "    # X = STORIES\n",
        "    X = []\n",
        "    # Xq = QUERY/QUESTION\n",
        "    Xq = []\n",
        "    # Y = CORRECT ANSWER\n",
        "    Y = []\n",
        "    \n",
        "    \n",
        "    for story, query, answer in data:\n",
        "        \n",
        "        # Grab the word index for every word in story\n",
        "        x = [word_index[word.lower()] for word in story]\n",
        "        # Grab the word index for every word in query\n",
        "        xq = [word_index[word.lower()] for word in query]\n",
        "        \n",
        "        # Grab the Answers (either Yes/No so we don't need to use list comprehension here)\n",
        "        # Index 0 is reserved so we're going to use + 1\n",
        "        y = np.zeros(len(word_index) + 1)\n",
        "        \n",
        "        # Now that y is all zeros and we know its just Yes/No , we can use numpy logic to create this assignment\n",
        "        #\n",
        "        y[word_index[answer]] = 1\n",
        "        \n",
        "        # Append each set of story,query, and answer to their respective holding lists\n",
        "        X.append(x)\n",
        "        Xq.append(xq)\n",
        "        Y.append(y)\n",
        "        \n",
        "    # Finally, pad the sequences based on their max length so the RNN can be trained on uniformly long sequences.\n",
        "        \n",
        "    # RETURN TUPLE FOR UNPACKING\n",
        "    return (pad_sequences(X, maxlen=max_story_len),pad_sequences(Xq, maxlen=max_question_len), np.array(Y))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LbzPaK6wyv3P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inputs_train, queries_train, answers_train = vectorize_stories(train_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rAQmgpfqyv3Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inputs_test, queries_test, answers_test = vectorize_stories(test_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJOKt5aNyv3S",
        "colab_type": "code",
        "outputId": "b73c71bf-c39e-4182-cd4e-520090fcae39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "inputs_test"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0,  0,  0, ..., 37, 19, 10],\n",
              "       [ 0,  0,  0, ..., 37,  2, 10],\n",
              "       [ 0,  0,  0, ..., 37,  2, 10],\n",
              "       ...,\n",
              "       [ 0,  0,  0, ..., 37, 21, 10],\n",
              "       [ 0,  0,  0, ..., 37,  2, 10],\n",
              "       [ 0,  0,  0, ..., 21, 22, 10]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NCh3Vp0jyv3T",
        "colab_type": "code",
        "outputId": "d3590d1a-d84e-46c1-ee86-da21dc925085",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "queries_test"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 4, 26,  5, 37, 20, 28],\n",
              "       [ 4, 26,  5, 37, 20, 28],\n",
              "       [ 4, 26,  5, 37,  2, 28],\n",
              "       ...,\n",
              "       [ 4, 11,  5, 37, 19, 28],\n",
              "       [ 4, 33,  5, 37,  2, 28],\n",
              "       [ 4, 11,  5, 37,  2, 28]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8V_MLjAzyv3W",
        "colab_type": "code",
        "outputId": "e163a62c-0176-4fb5-f8ae-399db218561f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "answers_test"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-KhwXD7pyv3Z",
        "colab_type": "code",
        "outputId": "bbb62280-564d-4a79-bcf5-5cf0806150a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "sum(answers_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0., 503.,   0.,   0.,   0.,   0.,   0., 497.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9UGvFGmOyv3b",
        "colab_type": "code",
        "outputId": "33b57a4a-02c8-49f9-c792-a58a0833e105",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tokenizer.word_index['yes']"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "29"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYWrXTHNyv3d",
        "colab_type": "code",
        "outputId": "d0783a64-7fe7-4d49-fb45-37859c7b207b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tokenizer.word_index['no']"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "23"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YxDuSaJ2yv3i",
        "colab_type": "text"
      },
      "source": [
        "## Creating the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JnKjO3Zkyv3i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential, Model\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.layers import Input, Activation, Dense, Permute, Dropout\n",
        "from keras.layers import add, dot, concatenate\n",
        "from keras.layers import LSTM"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rT_f2Bm4yv3j",
        "colab_type": "text"
      },
      "source": [
        "### Placeholders for Inputs\n",
        "\n",
        "Recall we technically have two inputs, stories and questions. So we need to use placeholders. `Input()` is used to instantiate a Keras tensor.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSbTbxVryv3l",
        "colab_type": "code",
        "outputId": "dbd83dde-9ae0-4e7e-f7fe-a27439925f70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "input_sequence = Input((max_story_len,))\n",
        "question = Input((max_question_len,))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0708 09:02:08.007291 140635252377472 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0708 09:02:08.054225 140635252377472 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "IDXbDczJyv3m",
        "colab_type": "text"
      },
      "source": [
        "### Building the Networks\n",
        "\n",
        "To understand why we chose this setup, make sure to read the paper we are using:\n",
        "\n",
        "* Sainbayar Sukhbaatar, Arthur Szlam, Jason Weston, Rob Fergus,\n",
        "  \"End-To-End Memory Networks\",\n",
        "  http://arxiv.org/abs/1503.08895"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "425fWKPMyv3m",
        "colab_type": "text"
      },
      "source": [
        "## Encoders\n",
        "\n",
        "### Input Encoder m"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Avs0gHh1yv3n",
        "colab_type": "code",
        "outputId": "7c80d6dd-a195-402f-e27c-7834c301b514",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "# Input gets embedded to a sequence of vectors\n",
        "input_encoder_m = Sequential()\n",
        "input_encoder_m.add(Embedding(input_dim=vocab_size,output_dim=64))\n",
        "input_encoder_m.add(Dropout(0.3))\n",
        "\n",
        "# This encoder will output:\n",
        "# (samples, story_maxlen, embedding_dim)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0708 09:02:08.072836 140635252377472 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0708 09:02:08.088219 140635252377472 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "W0708 09:02:08.096866 140635252377472 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BgXupFBPyv3o",
        "colab_type": "text"
      },
      "source": [
        "### Input Encoder c"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTnIZ5b4yv3q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# embed the input into a sequence of vectors of size query_maxlen\n",
        "input_encoder_c = Sequential()\n",
        "input_encoder_c.add(Embedding(input_dim=vocab_size,output_dim=max_question_len))\n",
        "input_encoder_c.add(Dropout(0.3))\n",
        "# output: (samples, story_maxlen, query_maxlen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8kZb1fq6yv3s",
        "colab_type": "text"
      },
      "source": [
        "### Question Encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6umyvm0yv3s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# embed the question into a sequence of vectors\n",
        "question_encoder = Sequential()\n",
        "question_encoder.add(Embedding(input_dim=vocab_size,\n",
        "                               output_dim=64,\n",
        "                               input_length=max_question_len))\n",
        "question_encoder.add(Dropout(0.3))\n",
        "# output: (samples, query_maxlen, embedding_dim)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0Ae5Odtyv3u",
        "colab_type": "text"
      },
      "source": [
        "### Encode the Sequences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wphLY7fyv3v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# encode input sequence and questions (which are indices)\n",
        "# to sequences of dense vectors\n",
        "input_encoded_m = input_encoder_m(input_sequence)\n",
        "input_encoded_c = input_encoder_c(input_sequence)\n",
        "question_encoded = question_encoder(question)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kaf2dv3Ryv3w",
        "colab_type": "text"
      },
      "source": [
        "##### Use dot product to compute the match between first input vector seq and the query"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBuyXRJVyv3x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# shape: `(samples, story_maxlen, query_maxlen)`\n",
        "match = dot([input_encoded_m, question_encoded], axes=(2, 2))\n",
        "match = Activation('softmax')(match)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGy88CFKyv3y",
        "colab_type": "text"
      },
      "source": [
        "#### Add this match matrix with the second input vector sequence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E71vIqXDyv3y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# add the match matrix with the second input vector sequence\n",
        "response = add([match, input_encoded_c])  # (samples, story_maxlen, query_maxlen)\n",
        "response = Permute((2, 1))(response)  # (samples, query_maxlen, story_maxlen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_RgHpAfyv3z",
        "colab_type": "text"
      },
      "source": [
        "#### Concatenate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qj_6TVHayv3z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# concatenate the match matrix with the question vector sequence\n",
        "answer = concatenate([response, question_encoded])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_SXTCleyv32",
        "colab_type": "code",
        "outputId": "cc10c485-146c-4ad8-cd9b-9e0734be6a1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "answer"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'concatenate_1/concat:0' shape=(?, 6, 220) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yb1ObBHYyv33",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Reduce with RNN (LSTM)\n",
        "answer = LSTM(32)(answer)  # (samples, 32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xieuliLcyv35",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Regularization with Dropout\n",
        "answer = Dropout(0.5)(answer)\n",
        "answer = Dense(vocab_size)(answer)  # (samples, vocab_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GACZVk_tyv36",
        "colab_type": "code",
        "outputId": "a3c917cb-b2c5-4804-abbe-d99484cc1e7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# we output a probability distribution over the vocabulary\n",
        "answer = Activation('softmax')(answer)\n",
        "\n",
        "# build the final model\n",
        "model = Model([input_sequence, question], answer)\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0708 09:02:08.525392 140635252377472 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0708 09:02:08.547636 140635252377472 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWtCm_LUyv37",
        "colab_type": "code",
        "outputId": "7bbfa48c-d762-49e9-f63c-928be6932e81",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 156)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            (None, 6)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "sequential_1 (Sequential)       multiple             2432        input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "sequential_3 (Sequential)       (None, 6, 64)        2432        input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dot_1 (Dot)                     (None, 156, 6)       0           sequential_1[1][0]               \n",
            "                                                                 sequential_3[1][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 156, 6)       0           dot_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "sequential_2 (Sequential)       multiple             228         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 156, 6)       0           activation_1[0][0]               \n",
            "                                                                 sequential_2[1][0]               \n",
            "__________________________________________________________________________________________________\n",
            "permute_1 (Permute)             (None, 6, 156)       0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 6, 220)       0           permute_1[0][0]                  \n",
            "                                                                 sequential_3[1][0]               \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   (None, 32)           32384       concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 32)           0           lstm_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 38)           1254        dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 38)           0           dense_1[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 38,730\n",
            "Trainable params: 38,730\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bqBUDZSYyv39",
        "colab_type": "code",
        "outputId": "df0a3525-f61c-472a-a18d-3fd7cae6314c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# train\n",
        "history = model.fit([inputs_train, queries_train], answers_train,batch_size=32,epochs=120,validation_data=([inputs_test, queries_test], answers_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0708 09:02:08.707439 140635252377472 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 10000 samples, validate on 1000 samples\n",
            "Epoch 1/120\n",
            "10000/10000 [==============================] - 9s 896us/step - loss: 0.8804 - acc: 0.5013 - val_loss: 0.6941 - val_acc: 0.4970\n",
            "Epoch 2/120\n",
            "10000/10000 [==============================] - 5s 466us/step - loss: 0.7041 - acc: 0.4982 - val_loss: 0.6968 - val_acc: 0.4970\n",
            "Epoch 3/120\n",
            "10000/10000 [==============================] - 5s 469us/step - loss: 0.6966 - acc: 0.5020 - val_loss: 0.6935 - val_acc: 0.4970\n",
            "Epoch 4/120\n",
            "10000/10000 [==============================] - 5s 460us/step - loss: 0.6951 - acc: 0.5029 - val_loss: 0.6934 - val_acc: 0.4970\n",
            "Epoch 5/120\n",
            "10000/10000 [==============================] - 5s 468us/step - loss: 0.6946 - acc: 0.5001 - val_loss: 0.6937 - val_acc: 0.4970\n",
            "Epoch 6/120\n",
            "10000/10000 [==============================] - 5s 469us/step - loss: 0.6954 - acc: 0.4943 - val_loss: 0.6938 - val_acc: 0.4970\n",
            "Epoch 7/120\n",
            "10000/10000 [==============================] - 5s 456us/step - loss: 0.6943 - acc: 0.4967 - val_loss: 0.6933 - val_acc: 0.4880\n",
            "Epoch 8/120\n",
            "10000/10000 [==============================] - 5s 471us/step - loss: 0.6938 - acc: 0.5091 - val_loss: 0.6934 - val_acc: 0.4920\n",
            "Epoch 9/120\n",
            "10000/10000 [==============================] - 5s 462us/step - loss: 0.6935 - acc: 0.5039 - val_loss: 0.6936 - val_acc: 0.4780\n",
            "Epoch 10/120\n",
            "10000/10000 [==============================] - 5s 467us/step - loss: 0.6908 - acc: 0.5280 - val_loss: 0.6904 - val_acc: 0.5210\n",
            "Epoch 11/120\n",
            "10000/10000 [==============================] - 5s 474us/step - loss: 0.6764 - acc: 0.5683 - val_loss: 0.6516 - val_acc: 0.6530\n",
            "Epoch 12/120\n",
            "10000/10000 [==============================] - 5s 463us/step - loss: 0.6355 - acc: 0.6393 - val_loss: 0.6064 - val_acc: 0.6770\n",
            "Epoch 13/120\n",
            "10000/10000 [==============================] - 5s 475us/step - loss: 0.6069 - acc: 0.6778 - val_loss: 0.5783 - val_acc: 0.7100\n",
            "Epoch 14/120\n",
            "10000/10000 [==============================] - 5s 471us/step - loss: 0.5815 - acc: 0.7001 - val_loss: 0.5414 - val_acc: 0.7410\n",
            "Epoch 15/120\n",
            "10000/10000 [==============================] - 5s 466us/step - loss: 0.5556 - acc: 0.7239 - val_loss: 0.5209 - val_acc: 0.7540\n",
            "Epoch 16/120\n",
            "10000/10000 [==============================] - 5s 471us/step - loss: 0.5297 - acc: 0.7445 - val_loss: 0.4913 - val_acc: 0.7730\n",
            "Epoch 17/120\n",
            "10000/10000 [==============================] - 5s 465us/step - loss: 0.5118 - acc: 0.7600 - val_loss: 0.4791 - val_acc: 0.7730\n",
            "Epoch 18/120\n",
            "10000/10000 [==============================] - 5s 461us/step - loss: 0.4959 - acc: 0.7694 - val_loss: 0.4591 - val_acc: 0.7880\n",
            "Epoch 19/120\n",
            "10000/10000 [==============================] - 5s 462us/step - loss: 0.4843 - acc: 0.7783 - val_loss: 0.4765 - val_acc: 0.7870\n",
            "Epoch 20/120\n",
            "10000/10000 [==============================] - 5s 462us/step - loss: 0.4705 - acc: 0.7858 - val_loss: 0.4440 - val_acc: 0.8010\n",
            "Epoch 21/120\n",
            "10000/10000 [==============================] - 5s 467us/step - loss: 0.4538 - acc: 0.7986 - val_loss: 0.4342 - val_acc: 0.8080\n",
            "Epoch 22/120\n",
            "10000/10000 [==============================] - 5s 461us/step - loss: 0.4484 - acc: 0.7967 - val_loss: 0.4344 - val_acc: 0.8020\n",
            "Epoch 23/120\n",
            "10000/10000 [==============================] - 5s 464us/step - loss: 0.4355 - acc: 0.8020 - val_loss: 0.4309 - val_acc: 0.8060\n",
            "Epoch 24/120\n",
            "10000/10000 [==============================] - 5s 465us/step - loss: 0.4262 - acc: 0.8045 - val_loss: 0.4204 - val_acc: 0.8080\n",
            "Epoch 25/120\n",
            "10000/10000 [==============================] - 5s 463us/step - loss: 0.4219 - acc: 0.8082 - val_loss: 0.4246 - val_acc: 0.8070\n",
            "Epoch 26/120\n",
            "10000/10000 [==============================] - 5s 463us/step - loss: 0.4177 - acc: 0.8108 - val_loss: 0.4185 - val_acc: 0.7940\n",
            "Epoch 27/120\n",
            "10000/10000 [==============================] - 5s 465us/step - loss: 0.4076 - acc: 0.8130 - val_loss: 0.4146 - val_acc: 0.8040\n",
            "Epoch 28/120\n",
            "10000/10000 [==============================] - 5s 466us/step - loss: 0.4018 - acc: 0.8152 - val_loss: 0.4220 - val_acc: 0.8060\n",
            "Epoch 29/120\n",
            "10000/10000 [==============================] - 5s 463us/step - loss: 0.3993 - acc: 0.8153 - val_loss: 0.4118 - val_acc: 0.8010\n",
            "Epoch 30/120\n",
            "10000/10000 [==============================] - 5s 461us/step - loss: 0.3972 - acc: 0.8162 - val_loss: 0.4144 - val_acc: 0.8090\n",
            "Epoch 31/120\n",
            "10000/10000 [==============================] - 5s 462us/step - loss: 0.3971 - acc: 0.8168 - val_loss: 0.4130 - val_acc: 0.8170\n",
            "Epoch 32/120\n",
            "10000/10000 [==============================] - 5s 461us/step - loss: 0.3937 - acc: 0.8173 - val_loss: 0.4116 - val_acc: 0.8060\n",
            "Epoch 33/120\n",
            "10000/10000 [==============================] - 5s 458us/step - loss: 0.3871 - acc: 0.8236 - val_loss: 0.4118 - val_acc: 0.8040\n",
            "Epoch 34/120\n",
            "10000/10000 [==============================] - 5s 466us/step - loss: 0.3857 - acc: 0.8211 - val_loss: 0.4022 - val_acc: 0.7870\n",
            "Epoch 35/120\n",
            "10000/10000 [==============================] - 5s 457us/step - loss: 0.3799 - acc: 0.8231 - val_loss: 0.4017 - val_acc: 0.8020\n",
            "Epoch 36/120\n",
            "10000/10000 [==============================] - 5s 455us/step - loss: 0.3786 - acc: 0.8237 - val_loss: 0.4022 - val_acc: 0.8100\n",
            "Epoch 37/120\n",
            "10000/10000 [==============================] - 5s 453us/step - loss: 0.3774 - acc: 0.8287 - val_loss: 0.4022 - val_acc: 0.8080\n",
            "Epoch 38/120\n",
            "10000/10000 [==============================] - 5s 453us/step - loss: 0.3724 - acc: 0.8306 - val_loss: 0.3959 - val_acc: 0.8200\n",
            "Epoch 39/120\n",
            "10000/10000 [==============================] - 5s 456us/step - loss: 0.3677 - acc: 0.8348 - val_loss: 0.3940 - val_acc: 0.8170\n",
            "Epoch 40/120\n",
            "10000/10000 [==============================] - 5s 460us/step - loss: 0.3569 - acc: 0.8400 - val_loss: 0.3698 - val_acc: 0.8330\n",
            "Epoch 41/120\n",
            "10000/10000 [==============================] - 5s 462us/step - loss: 0.3511 - acc: 0.8465 - val_loss: 0.3832 - val_acc: 0.8310\n",
            "Epoch 42/120\n",
            "10000/10000 [==============================] - 5s 459us/step - loss: 0.3513 - acc: 0.8453 - val_loss: 0.3699 - val_acc: 0.8260\n",
            "Epoch 43/120\n",
            "10000/10000 [==============================] - 5s 455us/step - loss: 0.3429 - acc: 0.8494 - val_loss: 0.3666 - val_acc: 0.8260\n",
            "Epoch 44/120\n",
            "10000/10000 [==============================] - 5s 453us/step - loss: 0.3372 - acc: 0.8529 - val_loss: 0.3619 - val_acc: 0.8320\n",
            "Epoch 45/120\n",
            "10000/10000 [==============================] - 5s 465us/step - loss: 0.3411 - acc: 0.8515 - val_loss: 0.3792 - val_acc: 0.8390\n",
            "Epoch 46/120\n",
            "10000/10000 [==============================] - 5s 454us/step - loss: 0.3343 - acc: 0.8537 - val_loss: 0.3736 - val_acc: 0.8410\n",
            "Epoch 47/120\n",
            "10000/10000 [==============================] - 5s 464us/step - loss: 0.3261 - acc: 0.8570 - val_loss: 0.3808 - val_acc: 0.8370\n",
            "Epoch 48/120\n",
            "10000/10000 [==============================] - 5s 476us/step - loss: 0.3295 - acc: 0.8608 - val_loss: 0.3547 - val_acc: 0.8400\n",
            "Epoch 49/120\n",
            "10000/10000 [==============================] - 5s 472us/step - loss: 0.3267 - acc: 0.8597 - val_loss: 0.3732 - val_acc: 0.8430\n",
            "Epoch 50/120\n",
            "10000/10000 [==============================] - 5s 465us/step - loss: 0.3259 - acc: 0.8586 - val_loss: 0.3616 - val_acc: 0.8360\n",
            "Epoch 51/120\n",
            "10000/10000 [==============================] - 5s 464us/step - loss: 0.3222 - acc: 0.8628 - val_loss: 0.3684 - val_acc: 0.8370\n",
            "Epoch 52/120\n",
            "10000/10000 [==============================] - 5s 457us/step - loss: 0.3209 - acc: 0.8591 - val_loss: 0.3741 - val_acc: 0.8420\n",
            "Epoch 53/120\n",
            "10000/10000 [==============================] - 5s 460us/step - loss: 0.3157 - acc: 0.8660 - val_loss: 0.3619 - val_acc: 0.8420\n",
            "Epoch 54/120\n",
            "10000/10000 [==============================] - 5s 458us/step - loss: 0.3120 - acc: 0.8649 - val_loss: 0.3866 - val_acc: 0.8420\n",
            "Epoch 55/120\n",
            "10000/10000 [==============================] - 5s 458us/step - loss: 0.3147 - acc: 0.8669 - val_loss: 0.3706 - val_acc: 0.8390\n",
            "Epoch 56/120\n",
            "10000/10000 [==============================] - 5s 455us/step - loss: 0.3126 - acc: 0.8674 - val_loss: 0.3628 - val_acc: 0.8380\n",
            "Epoch 57/120\n",
            "10000/10000 [==============================] - 5s 456us/step - loss: 0.3130 - acc: 0.8661 - val_loss: 0.3620 - val_acc: 0.8420\n",
            "Epoch 58/120\n",
            "10000/10000 [==============================] - 5s 452us/step - loss: 0.3088 - acc: 0.8659 - val_loss: 0.3704 - val_acc: 0.8380\n",
            "Epoch 59/120\n",
            "10000/10000 [==============================] - 5s 452us/step - loss: 0.3108 - acc: 0.8639 - val_loss: 0.3765 - val_acc: 0.8400\n",
            "Epoch 60/120\n",
            "10000/10000 [==============================] - 5s 464us/step - loss: 0.3071 - acc: 0.8702 - val_loss: 0.3944 - val_acc: 0.8360\n",
            "Epoch 61/120\n",
            "10000/10000 [==============================] - 5s 453us/step - loss: 0.2993 - acc: 0.8723 - val_loss: 0.3763 - val_acc: 0.8370\n",
            "Epoch 62/120\n",
            "10000/10000 [==============================] - 5s 454us/step - loss: 0.3050 - acc: 0.8699 - val_loss: 0.3810 - val_acc: 0.8400\n",
            "Epoch 63/120\n",
            "10000/10000 [==============================] - 5s 457us/step - loss: 0.3013 - acc: 0.8698 - val_loss: 0.3896 - val_acc: 0.8310\n",
            "Epoch 64/120\n",
            "10000/10000 [==============================] - 5s 454us/step - loss: 0.2940 - acc: 0.8722 - val_loss: 0.4166 - val_acc: 0.8340\n",
            "Epoch 65/120\n",
            "10000/10000 [==============================] - 5s 456us/step - loss: 0.2978 - acc: 0.8727 - val_loss: 0.3830 - val_acc: 0.8390\n",
            "Epoch 66/120\n",
            "10000/10000 [==============================] - 5s 456us/step - loss: 0.2969 - acc: 0.8717 - val_loss: 0.3702 - val_acc: 0.8250\n",
            "Epoch 67/120\n",
            "10000/10000 [==============================] - 5s 464us/step - loss: 0.2929 - acc: 0.8728 - val_loss: 0.3698 - val_acc: 0.8370\n",
            "Epoch 68/120\n",
            "10000/10000 [==============================] - 5s 458us/step - loss: 0.2911 - acc: 0.8743 - val_loss: 0.3749 - val_acc: 0.8320\n",
            "Epoch 69/120\n",
            "10000/10000 [==============================] - 5s 461us/step - loss: 0.2897 - acc: 0.8762 - val_loss: 0.3793 - val_acc: 0.8280\n",
            "Epoch 70/120\n",
            "10000/10000 [==============================] - 5s 455us/step - loss: 0.2848 - acc: 0.8764 - val_loss: 0.3940 - val_acc: 0.8310\n",
            "Epoch 71/120\n",
            "10000/10000 [==============================] - 5s 452us/step - loss: 0.2827 - acc: 0.8779 - val_loss: 0.3896 - val_acc: 0.8270\n",
            "Epoch 72/120\n",
            "10000/10000 [==============================] - 5s 451us/step - loss: 0.2871 - acc: 0.8743 - val_loss: 0.4020 - val_acc: 0.8310\n",
            "Epoch 73/120\n",
            "10000/10000 [==============================] - 5s 464us/step - loss: 0.2811 - acc: 0.8780 - val_loss: 0.4050 - val_acc: 0.8250\n",
            "Epoch 74/120\n",
            "10000/10000 [==============================] - 5s 455us/step - loss: 0.2822 - acc: 0.8815 - val_loss: 0.3932 - val_acc: 0.8340\n",
            "Epoch 75/120\n",
            "10000/10000 [==============================] - 5s 455us/step - loss: 0.2823 - acc: 0.8784 - val_loss: 0.3971 - val_acc: 0.8190\n",
            "Epoch 76/120\n",
            "10000/10000 [==============================] - 5s 456us/step - loss: 0.2731 - acc: 0.8826 - val_loss: 0.3997 - val_acc: 0.8260\n",
            "Epoch 77/120\n",
            "10000/10000 [==============================] - 5s 456us/step - loss: 0.2769 - acc: 0.8800 - val_loss: 0.3921 - val_acc: 0.8290\n",
            "Epoch 78/120\n",
            "10000/10000 [==============================] - 5s 462us/step - loss: 0.2767 - acc: 0.8824 - val_loss: 0.4114 - val_acc: 0.8250\n",
            "Epoch 79/120\n",
            "10000/10000 [==============================] - 5s 457us/step - loss: 0.2707 - acc: 0.8854 - val_loss: 0.4396 - val_acc: 0.8360\n",
            "Epoch 80/120\n",
            "10000/10000 [==============================] - 5s 462us/step - loss: 0.2712 - acc: 0.8860 - val_loss: 0.4113 - val_acc: 0.8300\n",
            "Epoch 81/120\n",
            "10000/10000 [==============================] - 5s 464us/step - loss: 0.2752 - acc: 0.8861 - val_loss: 0.4375 - val_acc: 0.8260\n",
            "Epoch 82/120\n",
            "10000/10000 [==============================] - 5s 457us/step - loss: 0.2714 - acc: 0.8864 - val_loss: 0.4287 - val_acc: 0.8190\n",
            "Epoch 83/120\n",
            "10000/10000 [==============================] - 5s 455us/step - loss: 0.2705 - acc: 0.8826 - val_loss: 0.4405 - val_acc: 0.8270\n",
            "Epoch 84/120\n",
            "10000/10000 [==============================] - 5s 471us/step - loss: 0.2734 - acc: 0.8823 - val_loss: 0.4219 - val_acc: 0.8360\n",
            "Epoch 85/120\n",
            "10000/10000 [==============================] - 5s 452us/step - loss: 0.2687 - acc: 0.8863 - val_loss: 0.4103 - val_acc: 0.8190\n",
            "Epoch 86/120\n",
            "10000/10000 [==============================] - 5s 454us/step - loss: 0.2707 - acc: 0.8859 - val_loss: 0.4131 - val_acc: 0.8250\n",
            "Epoch 87/120\n",
            "10000/10000 [==============================] - 5s 455us/step - loss: 0.2641 - acc: 0.8880 - val_loss: 0.4207 - val_acc: 0.8310\n",
            "Epoch 88/120\n",
            "10000/10000 [==============================] - 5s 452us/step - loss: 0.2640 - acc: 0.8867 - val_loss: 0.4561 - val_acc: 0.8200\n",
            "Epoch 89/120\n",
            "10000/10000 [==============================] - 5s 452us/step - loss: 0.2624 - acc: 0.8880 - val_loss: 0.4243 - val_acc: 0.8240\n",
            "Epoch 90/120\n",
            "10000/10000 [==============================] - 5s 454us/step - loss: 0.2581 - acc: 0.8934 - val_loss: 0.4831 - val_acc: 0.8250\n",
            "Epoch 91/120\n",
            "10000/10000 [==============================] - 4s 450us/step - loss: 0.2597 - acc: 0.8902 - val_loss: 0.4395 - val_acc: 0.8300\n",
            "Epoch 92/120\n",
            "10000/10000 [==============================] - 5s 455us/step - loss: 0.2559 - acc: 0.8940 - val_loss: 0.4305 - val_acc: 0.8230\n",
            "Epoch 93/120\n",
            "10000/10000 [==============================] - 5s 454us/step - loss: 0.2590 - acc: 0.8920 - val_loss: 0.4593 - val_acc: 0.8360\n",
            "Epoch 94/120\n",
            "10000/10000 [==============================] - 5s 457us/step - loss: 0.2549 - acc: 0.8961 - val_loss: 0.4575 - val_acc: 0.8260\n",
            "Epoch 95/120\n",
            "10000/10000 [==============================] - 5s 452us/step - loss: 0.2553 - acc: 0.8917 - val_loss: 0.4465 - val_acc: 0.8330\n",
            "Epoch 96/120\n",
            "10000/10000 [==============================] - 5s 459us/step - loss: 0.2605 - acc: 0.8904 - val_loss: 0.4350 - val_acc: 0.8300\n",
            "Epoch 97/120\n",
            "10000/10000 [==============================] - 5s 451us/step - loss: 0.2491 - acc: 0.8936 - val_loss: 0.4641 - val_acc: 0.8280\n",
            "Epoch 98/120\n",
            "10000/10000 [==============================] - 5s 453us/step - loss: 0.2468 - acc: 0.8945 - val_loss: 0.4957 - val_acc: 0.8300\n",
            "Epoch 99/120\n",
            "10000/10000 [==============================] - 5s 454us/step - loss: 0.2456 - acc: 0.8937 - val_loss: 0.4814 - val_acc: 0.8250\n",
            "Epoch 100/120\n",
            "10000/10000 [==============================] - 5s 460us/step - loss: 0.2511 - acc: 0.8953 - val_loss: 0.4663 - val_acc: 0.8270\n",
            "Epoch 101/120\n",
            "10000/10000 [==============================] - 5s 464us/step - loss: 0.2512 - acc: 0.8953 - val_loss: 0.4734 - val_acc: 0.8170\n",
            "Epoch 102/120\n",
            "10000/10000 [==============================] - 5s 456us/step - loss: 0.2438 - acc: 0.8979 - val_loss: 0.4800 - val_acc: 0.8280\n",
            "Epoch 103/120\n",
            "10000/10000 [==============================] - 5s 457us/step - loss: 0.2525 - acc: 0.8971 - val_loss: 0.4706 - val_acc: 0.8280\n",
            "Epoch 104/120\n",
            "10000/10000 [==============================] - 5s 454us/step - loss: 0.2500 - acc: 0.8952 - val_loss: 0.4889 - val_acc: 0.8230\n",
            "Epoch 105/120\n",
            "10000/10000 [==============================] - 5s 456us/step - loss: 0.2414 - acc: 0.8981 - val_loss: 0.4708 - val_acc: 0.8260\n",
            "Epoch 106/120\n",
            "10000/10000 [==============================] - 5s 453us/step - loss: 0.2458 - acc: 0.8934 - val_loss: 0.4909 - val_acc: 0.8250\n",
            "Epoch 107/120\n",
            "10000/10000 [==============================] - 5s 465us/step - loss: 0.2381 - acc: 0.8981 - val_loss: 0.5155 - val_acc: 0.8320\n",
            "Epoch 108/120\n",
            "10000/10000 [==============================] - 4s 450us/step - loss: 0.2365 - acc: 0.9018 - val_loss: 0.4959 - val_acc: 0.8260\n",
            "Epoch 109/120\n",
            "10000/10000 [==============================] - 5s 456us/step - loss: 0.2393 - acc: 0.8991 - val_loss: 0.4811 - val_acc: 0.8230\n",
            "Epoch 110/120\n",
            "10000/10000 [==============================] - 5s 456us/step - loss: 0.2442 - acc: 0.8971 - val_loss: 0.4721 - val_acc: 0.8210\n",
            "Epoch 111/120\n",
            "10000/10000 [==============================] - 4s 450us/step - loss: 0.2365 - acc: 0.8986 - val_loss: 0.4778 - val_acc: 0.8360\n",
            "Epoch 112/120\n",
            "10000/10000 [==============================] - 5s 454us/step - loss: 0.2367 - acc: 0.9012 - val_loss: 0.4979 - val_acc: 0.8240\n",
            "Epoch 113/120\n",
            "10000/10000 [==============================] - 5s 453us/step - loss: 0.2388 - acc: 0.8991 - val_loss: 0.4692 - val_acc: 0.8240\n",
            "Epoch 114/120\n",
            "10000/10000 [==============================] - 5s 462us/step - loss: 0.2346 - acc: 0.9005 - val_loss: 0.5030 - val_acc: 0.8260\n",
            "Epoch 115/120\n",
            "10000/10000 [==============================] - 5s 469us/step - loss: 0.2331 - acc: 0.9002 - val_loss: 0.5143 - val_acc: 0.8340\n",
            "Epoch 116/120\n",
            "10000/10000 [==============================] - 5s 468us/step - loss: 0.2293 - acc: 0.9018 - val_loss: 0.5025 - val_acc: 0.8150\n",
            "Epoch 117/120\n",
            "10000/10000 [==============================] - 5s 470us/step - loss: 0.2296 - acc: 0.9047 - val_loss: 0.4886 - val_acc: 0.8080\n",
            "Epoch 118/120\n",
            "10000/10000 [==============================] - 5s 467us/step - loss: 0.2263 - acc: 0.9064 - val_loss: 0.5204 - val_acc: 0.8100\n",
            "Epoch 119/120\n",
            "10000/10000 [==============================] - 5s 461us/step - loss: 0.2281 - acc: 0.9069 - val_loss: 0.5225 - val_acc: 0.8200\n",
            "Epoch 120/120\n",
            "10000/10000 [==============================] - 5s 464us/step - loss: 0.2232 - acc: 0.9045 - val_loss: 0.5558 - val_acc: 0.8210\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XYKJ5IvPyv3-",
        "colab_type": "text"
      },
      "source": [
        "### Saving the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TxnrPx4Ryv3-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filename = 'chatbot_120_epochs.h5'\n",
        "model.save(filename)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVa_PTrQyv3_",
        "colab_type": "text"
      },
      "source": [
        "## Evaluating the Model\n",
        "\n",
        "### Plotting Out Training History"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0iCZcBKIyv3_",
        "colab_type": "code",
        "outputId": "fc22057f-ce75-4811-fb23-4bf74d1ce1c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "print(history.history.keys())\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\npar9P3TocQjGktsvAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NY-63a4Cyv4B",
        "colab_type": "text"
      },
      "source": [
        "### Evaluating on Given Test Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ts10Pde4yv4B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_weights(filename)\n",
        "pred_results = model.predict(([inputs_test, queries_test]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNZ7hE33yv4C",
        "colab_type": "code",
        "outputId": "c681d17d-a375-4063-b9be-ddd0f326ea4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "test_data[0][0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Mary',\n",
              " 'got',\n",
              " 'the',\n",
              " 'milk',\n",
              " 'there',\n",
              " '.',\n",
              " 'John',\n",
              " 'moved',\n",
              " 'to',\n",
              " 'the',\n",
              " 'bedroom',\n",
              " '.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WErHqjXyv4E",
        "colab_type": "code",
        "outputId": "67a7fd2f-2bee-439a-edc1-63a161804ed4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "story =' '.join(word for word in test_data[0][0])\n",
        "print(story)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mary got the milk there . John moved to the bedroom .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nz4pGtmHyv4F",
        "colab_type": "code",
        "outputId": "c0d21ab7-cc50-4357-a789-b1a4122f2f11",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "query = ' '.join(word for word in test_data[0][1])\n",
        "print(query)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Is John in the kitchen ?\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BskbuU_fyv4G",
        "colab_type": "code",
        "outputId": "3ea90f0f-1af8-44c2-a436-a5ed563b4f86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"True Test Answer from Data is:\",test_data[0][2])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True Test Answer from Data is: no\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iIgdL2Q2yv4H",
        "colab_type": "code",
        "outputId": "4d049a57-34ee-4631-d695-c1a2ff76ee47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#Generate prediction from model\n",
        "val_max = np.argmax(pred_results[0])\n",
        "\n",
        "for key, val in tokenizer.word_index.items():\n",
        "    if val == val_max:\n",
        "        k = key\n",
        "\n",
        "print(\"Predicted answer is: \", k)\n",
        "print(\"Probability of certainty was: \", pred_results[0][val_max])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted answer is:  no\n",
            "Probability of certainty was:  0.9998808\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wz1MsSJyv4J",
        "colab_type": "text"
      },
      "source": [
        "## Writing Your Own Stories and Questions\n",
        "\n",
        "Remember you can only use words from the existing vocab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5EdXqJVXyv4J",
        "colab_type": "code",
        "outputId": "0443197e-0e0d-4ca8-9dd1-8b365283c119",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "vocab"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "set()"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7lTe9Kfyv4L",
        "colab_type": "code",
        "outputId": "93599838-07b5-4beb-9d45-5617c0e3e1ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "# Note the whitespace of the periods\n",
        "my_story = \"John left the kitchen . Sandra dropped the football in the garden .\"\n",
        "my_story.split()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['John',\n",
              " 'left',\n",
              " 'the',\n",
              " 'kitchen',\n",
              " '.',\n",
              " 'Sandra',\n",
              " 'dropped',\n",
              " 'the',\n",
              " 'football',\n",
              " 'in',\n",
              " 'the',\n",
              " 'garden',\n",
              " '.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGSI6cIryv4N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "my_question = \"Is the football in the garden ?\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hdCPCCkKyv4O",
        "colab_type": "code",
        "outputId": "cbb442e2-00dd-41b7-b1bb-75335881ab42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "my_question.split()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Is', 'the', 'football', 'in', 'the', 'garden', '?']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nyAcLmYyv4Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mydata = [(my_story.split(),my_question.split(),'yes')]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n24vkhRpyv4S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "my_story,my_ques,my_ans = vectorize_stories(mydata)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vTJ74mYyv4T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred_results = model.predict(([ my_story, my_ques]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mnzqa23Jyv4U",
        "colab_type": "code",
        "outputId": "00e01175-1d63-4a5f-8c7c-d27b1e11438d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#Generate prediction from model\n",
        "val_max = np.argmax(pred_results[0])\n",
        "\n",
        "for key, val in tokenizer.word_index.items():\n",
        "    if val == val_max:\n",
        "        k = key\n",
        "\n",
        "print(\"Predicted answer is: \", k)\n",
        "print(\"Probability of certainty was: \", pred_results[0][val_max])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted answer is:  yes\n",
            "Probability of certainty was:  0.9461096\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q8rT7B0-yv4W",
        "colab_type": "text"
      },
      "source": [
        "# Great Job!"
      ]
    }
  ]
}